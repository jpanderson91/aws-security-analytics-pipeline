# Cloud Analytics Platform (CAP)

ğŸ›¡ï¸ **Enterprise-grade security analytics pipeline for real-time threat detection and compliance monitoring**

## ğŸ¯ Overview

The CAP (Cloud Analytics Platform) demonstrates a complete AWS-native security analytics solution that ingests, processes, and analyzes security events in real-time. This pipeline showcases modern data engineering patterns, serverless architectures, and advanced analytics capabilities.

### ğŸ—ï¸ Architecture Highlights

- **Real-time Event Ingestion**: Apache Kafka (MSK) for high-throughput data streaming
- **Scalable Processing**: ECS Fargate containers for event processing and enrichment
- **Data Lake Architecture**: S3-based Bronze/Silver/Gold data tiering
- **Serverless Analytics**: Lambda functions for real-time event processing
- **Customer APIs**: API Gateway endpoints for secure data access
- **Business Intelligence**: QuickSight dashboards for security metrics visualization
- **Infrastructure as Code**: Terraform for complete resource provisioning

## ğŸš€ Quick Start

### Prerequisites

- AWS CLI configured with appropriate permissions
- Terraform >= 1.0
- Python 3.9+
- Docker (for local development)

### 1. Environment Setup

```bash
# Install Python dependencies
pip install -r requirements.txt

# Configure AWS SSO (recommended)
aws configure sso
```

### 2. Phase-by-Phase Deployment

```bash
# Phase 1: Data Ingestion (Kafka/MSK)
python scripts/setup_phase1_kafka.py

# Phase 2: Data Processing (ECS/Lambda)
python scripts/setup_phase2_processing.py

# Phase 3: Analytics & APIs (QuickSight/API Gateway)
python scripts/setup_phase3_analytics.py
```

### 3. Validation & Testing

```bash
# Run complete validation
python scripts/run_complete_validation.py

# Test end-to-end flow
python scripts/run_full_demo.py
```

## ğŸ“ Project Structure

```
cap-security-analytics-pipeline/
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md         # Technical architecture
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md     # Detailed deployment guide
â”‚   â”œâ”€â”€ DEMO_SCRIPT.md          # Demo recording script
â”‚   â””â”€â”€ screenshots/            # Architecture diagrams & screenshots
â”œâ”€â”€ terraform/                  # Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf                 # Main Terraform configuration
â”‚   â”œâ”€â”€ variables.tf            # Input variables
â”‚   â”œâ”€â”€ outputs.tf              # Output values
â”‚   â””â”€â”€ dashboards.tf           # QuickSight dashboard configuration
â”œâ”€â”€ src/                        # Application source code
â”‚   â”œâ”€â”€ lambda/                 # Lambda function code
â”‚   â”‚   â””â”€â”€ event_processor/    # Event processing Lambda
â”‚   â””â”€â”€ deploy.py               # Deployment utilities
â”œâ”€â”€ scripts/                    # Automation scripts
â”‚   â”œâ”€â”€ setup_phase1_kafka.py         # Phase 1 deployment
â”‚   â”œâ”€â”€ setup_phase2_processing.py    # Phase 2 deployment
â”‚   â”œâ”€â”€ setup_phase3_analytics.py     # Phase 3 deployment
â”‚   â”œâ”€â”€ verify_phase*.py              # Phase validation scripts
â”‚   â”œâ”€â”€ run_complete_validation.py    # Complete validation runner
â”‚   â”œâ”€â”€ run_full_demo.py              # Demo orchestration
â”‚   â””â”€â”€ produce_security_events.py    # Test data generation
â””â”€â”€ tests/                      # Testing scripts
    â”œâ”€â”€ test_phase2_dataflow.py        # Data flow testing
    â””â”€â”€ test_customer_apis.py          # API testing
```

## ğŸ”§ Core Components

### Phase 1: Data Ingestion
- **Amazon MSK**: Managed Kafka cluster for event streaming
- **Security Groups**: Network isolation and access control
- **Topic Management**: Automated Kafka topic creation and configuration

### Phase 2: Data Processing
- **ECS Fargate**: Containerized event processors
- **AWS Lambda**: Real-time event processing functions
- **S3 Data Lake**: Bronze/Silver/Gold data architecture
- **AWS Glue**: Data catalog and ETL jobs

### Phase 3: Analytics & APIs
- **Amazon Athena**: Serverless SQL analytics
- **Amazon QuickSight**: Business intelligence dashboards
- **API Gateway**: RESTful APIs for data access
- **DynamoDB**: Customer metadata storage

## ğŸ­ Demo Scenarios

The pipeline includes three demonstration scenarios:

1. **Security Incident Response**: Real-time threat detection and alerting
2. **Customer Onboarding**: New customer data integration flow
3. **Real-time Analytics**: Live security metrics and dashboards

## ğŸ“Š Key Features

- âœ… **Real-time Processing**: Sub-second event processing and alerting
- âœ… **Scalable Architecture**: Auto-scaling based on demand
- âœ… **Cost Optimized**: Serverless and spot instance utilization
- âœ… **Security First**: IAM roles, VPC isolation, encryption at rest/transit
- âœ… **Monitoring**: CloudWatch metrics and custom dashboards
- âœ… **DevOps Ready**: Infrastructure as Code with Terraform

## ğŸ’° Cost Optimization

The pipeline is designed for cost efficiency:
- Serverless Lambda for event processing
- ECS Spot instances for batch processing
- S3 Intelligent Tiering for storage optimization
- MSK provisioned throughput scaling

Expected monthly cost: **$50-150** (depending on data volume)

## ğŸ” Monitoring & Observability

- **CloudWatch Dashboards**: Real-time metrics and alarms
- **Custom Metrics**: Business KPIs and operational metrics
- **Distributed Tracing**: End-to-end request tracking
- **Log Aggregation**: Centralized logging with search capabilities

## ğŸ¤ Contributing

This project demonstrates enterprise-grade AWS security analytics capabilities. For questions or discussions about the architecture and implementation decisions, please review the documentation in the `docs/` directory.

## ğŸ“„ License

This project is available under the MIT License. See the LICENSE file for details.

---

**Built with â¤ï¸ using AWS native services and modern data engineering practices**
